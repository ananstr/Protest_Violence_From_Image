{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "id": "3VIHRMKRw9CG"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import math\n",
    "import imageio\n",
    "from os import listdir\n",
    "import warnings\n",
    "import filecmp\n",
    "from PIL import Image\n",
    "import gc\n",
    "import psutil\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "from time import ctime\n",
    "import cv2\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProtestDataset(Dataset):\n",
    "    def __init__(self, images, labels=None, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        \n",
    "        # Convert to PIL Image if necessary (for transforms)\n",
    "        if self.transform:\n",
    "            image = Image.fromarray((image * 255).astype(np.uint8))\n",
    "            image = self.transform(image)\n",
    "        else:\n",
    "            # PyTorch expects image data in format [C, H, W]\n",
    "            image = torch.tensor(image.transpose(2, 0, 1), dtype=torch.float32)\n",
    "        \n",
    "        if self.labels is not None:\n",
    "            label = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "            return image, label\n",
    "        else:\n",
    "            return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProtestResNet(nn.Module):\n",
    "    def __init__(self, num_classes=1):\n",
    "        super(ProtestResNet, self).__init__()\n",
    "        # Load pre-trained ResNet50\n",
    "        self.resnet = models.resnet50(pretrained=True)\n",
    "        \n",
    "        # Replace the final fully connected layer for our binary classification\n",
    "        num_features = self.resnet.fc.in_features\n",
    "        \n",
    "        # Remove the original FC layer and add our custom classifier\n",
    "        self.resnet.fc = nn.Identity()\n",
    "        \n",
    "        # Custom classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(num_features, 2048),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.BatchNorm1d(2048),\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, num_classes),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locate files\n",
    "train_folder = r'data\\train'\n",
    "test_folder = r'data\\test'\n",
    "train_csv = r'data\\annot_train.txt'\n",
    "test_csv = r'data\\annot_test.txt'\n",
    "annot_train = pd.read_csv(train_csv, sep='\\t')\n",
    "annot_test = pd.read_csv(test_csv, sep='\\t')\n",
    "\n",
    "# Replace \"-\" with 0 due to the way the file is written\n",
    "annot_train = annot_train.replace(\"-\", 0)\n",
    "annot_test = annot_test.replace(\"-\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data loading: Wed Jun 18 13:24:00 2025\n",
      "Loading training data from data\\train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading training images:   0%|          | 0/32611 [00:00<?, ?it/s]C:\\Users\\matia\\AppData\\Local\\Temp\\ipykernel_17768\\4125815065.py:20: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  image = imageio.imread(filepath)\n",
      "Loading training images: 100%|██████████| 32611/32611 [04:16<00:00, 127.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test data from data\\test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading test images:   0%|          | 0/8153 [00:00<?, ?it/s]C:\\Users\\matia\\AppData\\Local\\Temp\\ipykernel_17768\\4125815065.py:51: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  image = imageio.imread(filepath)\n",
      "Loading test images: 100%|██████████| 8153/8153 [00:45<00:00, 180.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading completed: Wed Jun 18 13:29:04 2025\n",
      "Training data: 32611 images\n",
      "Test data: 8153 images\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "print(f\"Starting data loading: {ctime()}\")\n",
    "train_images = []\n",
    "train_labels = []\n",
    "test_images = []\n",
    "test_labels = []\n",
    "\n",
    "# Load training data\n",
    "print(f\"Loading training data from {train_folder}\")\n",
    "for file in tqdm(os.listdir(train_folder), desc=\"Loading training images\"):\n",
    "    if file.endswith('.jpg') or file.endswith('.png') or file.endswith('.jpeg'):\n",
    "        try:\n",
    "            # Get the protest label for this image\n",
    "            protest_value = 0\n",
    "            if file in annot_train['fname'].values:\n",
    "                protest_value = annot_train[annot_train.fname == file]['protest'].iloc[0]\n",
    "            \n",
    "            # Read and preprocess image\n",
    "            filepath = os.path.join(train_folder, file)\n",
    "            image = imageio.imread(filepath)\n",
    "            \n",
    "            # Handle grayscale images (convert to RGB)\n",
    "            if len(image.shape) == 2:\n",
    "                image = np.stack([image, image, image], axis=2)\n",
    "            elif image.shape[2] == 4:  # Handle RGBA images\n",
    "                image = image[:, :, :3]\n",
    "                \n",
    "            # Resize image to 50x50 (initial preprocessing)\n",
    "            image = cv2.resize(image, (50, 50))\n",
    "            image = image / 255.0  # Normalize to [0,1]\n",
    "            \n",
    "            # Add to datasets\n",
    "            train_images.append(image)\n",
    "            train_labels.append(protest_value)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file}: {e}\")\n",
    "\n",
    "# Load test data\n",
    "print(f\"Loading test data from {test_folder}\")\n",
    "for file in tqdm(os.listdir(test_folder), desc=\"Loading test images\"):\n",
    "    if file.endswith('.jpg') or file.endswith('.png') or file.endswith('.jpeg'):\n",
    "        try:\n",
    "            # Get the protest label for this image if available\n",
    "            protest_value = 0\n",
    "            if file in annot_test['fname'].values:\n",
    "                protest_value = annot_test[annot_test.fname == file]['protest'].iloc[0]\n",
    "            \n",
    "            # Read and preprocess image\n",
    "            filepath = os.path.join(test_folder, file)\n",
    "            image = imageio.imread(filepath)\n",
    "            \n",
    "            # Handle grayscale images (convert to RGB)\n",
    "            if len(image.shape) == 2:\n",
    "                image = np.stack([image, image, image], axis=2)\n",
    "            elif image.shape[2] == 4:  # Handle RGBA images\n",
    "                image = image[:, :, :3]\n",
    "                \n",
    "            # Resize image to 50x50 (initial preprocessing)\n",
    "            image = cv2.resize(image, (50, 50))\n",
    "            image = image / 255.0  # Normalize to [0,1]\n",
    "            \n",
    "            # Add to datasets\n",
    "            test_images.append(image)\n",
    "            test_labels.append(protest_value)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file}: {e}\")\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "train_images = np.array(train_images)\n",
    "train_labels = np.array(train_labels)\n",
    "test_images = np.array(test_images)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "print(f\"Data loading completed: {ctime()}\")\n",
    "print(f\"Training data: {train_images.shape[0]} images\")\n",
    "print(f\"Test data: {test_images.shape[0]} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training class distribution: Non-protest: 23295, Protest: 9316\n",
      "Test class distribution: Non-protest: 5810, Protest: 2343\n"
     ]
    }
   ],
   "source": [
    "# Check class distribution\n",
    "train_class_counts = np.bincount(train_labels.astype(int))\n",
    "test_class_counts = np.bincount(test_labels.astype(int))\n",
    "\n",
    "print(f\"Training class distribution: Non-protest: {train_class_counts[0]}, Protest: {train_class_counts[1] if len(train_class_counts) > 1 else 0}\")\n",
    "print(f\"Test class distribution: Non-protest: {test_class_counts[0]}, Protest: {test_class_counts[1] if len(test_class_counts) > 1 else 0}\")\n",
    "\n",
    "# PyTorch specific preprocessing\n",
    "# Since ResNet expects 224x224 images, we'll need to resize\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # ResNet expects 224x224 images\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ImageNet normalization\n",
    "])\n",
    "\n",
    "# Split training data for validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_images, train_labels, test_size=0.2, random_state=42, stratify=train_labels)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = ProtestDataset(X_train, y_train, transform=transform)\n",
    "val_dataset = ProtestDataset(X_val, y_val, transform=transform)\n",
    "test_dataset = ProtestDataset(test_images, test_labels, transform=transform)\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 32  # Increased batch size if your GPU can handle it\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize the model\n",
    "model = ProtestResNet(num_classes=1)\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "lr = 1e-3\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, nesterov=True, weight_decay=1e-6)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=3)\n",
    "\n",
    "# Early stopping parameters\n",
    "early_stopping_patience = 5\n",
    "best_val_acc = 0.0\n",
    "no_improve_epochs = 0\n",
    "\n",
    "# Training function\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=10):\n",
    "    global best_val_acc, no_improve_epochs\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accs = []\n",
    "    val_accs = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\"):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device).view(-1, 1)  # Reshape to match output\n",
    "            \n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Statistics\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            predicted = (outputs > 0.5).float()\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_acc = correct / total\n",
    "        train_losses.append(epoch_loss)\n",
    "        train_accs.append(epoch_acc)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Val]\"):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device).view(-1, 1)\n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                # Statistics\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                predicted = (outputs > 0.5).float()\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "            \n",
    "        val_loss = val_loss / len(val_loader.dataset)\n",
    "        val_acc = correct / total\n",
    "        val_losses.append(val_loss)\n",
    "        val_accs.append(val_acc)\n",
    "        \n",
    "        # Update the learning rate based on validation accuracy\n",
    "        scheduler.step(val_acc)\n",
    "        \n",
    "        # Check for improvement for early stopping\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), 'best_model.pt')\n",
    "            print(f\"Saved new best model with validation accuracy: {val_acc:.4f}\")\n",
    "            no_improve_epochs = 0\n",
    "        else:\n",
    "            no_improve_epochs += 1\n",
    "            if no_improve_epochs >= early_stopping_patience:\n",
    "                print(f\"Early stopping triggered after {epoch+1} epochs\")\n",
    "                break\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - \"\n",
    "              f\"Train Loss: {epoch_loss:.4f}, Train Acc: {epoch_acc:.4f}, \"\n",
    "              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'train_loss': train_losses,\n",
    "        'val_loss': val_losses,\n",
    "        'train_acc': train_accs,\n",
    "        'val_acc': val_accs\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]:  67%|██████▋   | 545/816 [29:07<14:28,  3.21s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting training...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Load the best model\u001b[39;00m\n\u001b[0;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_model.pt\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "Cell \u001b[1;32mIn[21], line 44\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[0;32m     41\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Backward pass and optimize\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# Statistics\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\matia\\OneDrive\\Escritorio\\Nastia_BSE\\ImageProcessing\\Violent_Protest\\.venv\\lib\\site-packages\\torch\\_tensor.py:648\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    640\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    641\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    646\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    647\u001b[0m     )\n\u001b[1;32m--> 648\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    650\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\matia\\OneDrive\\Escritorio\\Nastia_BSE\\ImageProcessing\\Violent_Protest\\.venv\\lib\\site-packages\\torch\\autograd\\__init__.py:353\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    348\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    350\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 353\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    361\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\matia\\OneDrive\\Escritorio\\Nastia_BSE\\ImageProcessing\\Violent_Protest\\.venv\\lib\\site-packages\\torch\\autograd\\graph.py:824\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    822\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    823\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 824\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    825\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    826\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    827\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    828\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "num_epochs = 10\n",
    "print(\"Starting training...\")\n",
    "history = train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=num_epochs)\n",
    "\n",
    "# Load the best model\n",
    "model.load_state_dict(torch.load('best_model.pt'))\n",
    "print(\"Loaded best model from checkpoint\")\n",
    "\n",
    "# Make sure datasets have proper __len__ method\n",
    "# This is a safer approach to add the method to the class if it's missing\n",
    "if not hasattr(test_dataset.__class__, '__len__'):\n",
    "    def dataset_len(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    # Add the method to the class itself, not the instance\n",
    "    setattr(test_dataset.__class__, '__len__', dataset_len)\n",
    "\n",
    "# No need to add it separately to train and val datasets, as they should \n",
    "# be instances of the same class as test_dataset\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['train_acc'], label='Train Accuracy')\n",
    "plt.plot(history['val_acc'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Model Accuracy')\n",
    "\n",
    "# Mark the best model\n",
    "best_epoch = np.argmax(history['val_acc'])\n",
    "plt.plot(best_epoch, history['val_acc'][best_epoch], 'rx', markersize=10)\n",
    "plt.annotate(f\"Best: {history['val_acc'][best_epoch]:.4f}\", \n",
    "             (float(best_epoch), float(history['val_acc'][best_epoch])),\n",
    "             xytext=(float(best_epoch+0.5), float(history['val_acc'][best_epoch])),\n",
    "             fontsize=9)\n",
    "\n",
    "# Plot loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['train_loss'], label='Train Loss')\n",
    "plt.plot(history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Model Loss')\n",
    "\n",
    "# Mark the best model\n",
    "best_epoch_loss = np.argmin(history['val_loss'])\n",
    "plt.plot(best_epoch_loss, history['val_loss'][best_epoch_loss], 'rx', markersize=10)\n",
    "plt.annotate(f\"Best: {history['val_loss'][best_epoch_loss]:.4f}\", \n",
    "             (float(best_epoch_loss), float(history['val_loss'][best_epoch_loss])),\n",
    "             xytext=(float(best_epoch_loss+0.5), float(history['val_loss'][best_epoch_loss])),\n",
    "             fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluate on test set\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "test_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in tqdm(test_loader, desc=\"Evaluating test data\"):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device).view(-1, 1)\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        test_loss += loss.item() * inputs.size(0)\n",
    "        predicted = (outputs > 0.5).float()\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # Store predictions and labels for metrics\n",
    "        all_preds.extend(predicted.cpu().numpy().flatten())\n",
    "        all_labels.extend(labels.cpu().numpy().flatten())\n",
    "\n",
    "test_loss = test_loss / len(test_loader.dataset)\n",
    "test_accuracy = correct / total\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Calculate and print additional metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(all_labels, all_preds))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(conf_matrix, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "\n",
    "classes = ['Non-Protest', 'Protest']\n",
    "tick_marks = np.arange(len(classes))\n",
    "plt.xticks(tick_marks, classes, rotation=45)\n",
    "plt.yticks(tick_marks, classes)\n",
    "\n",
    "# Add text annotations\n",
    "thresh = conf_matrix.max() / 2.0\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        plt.text(j, i, format(conf_matrix[i, j], 'd'),\n",
    "                horizontalalignment=\"center\",\n",
    "                color=\"white\" if conf_matrix[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()\n",
    "\n",
    "# Save the final model\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'val_accuracy': best_val_acc,\n",
    "    'test_accuracy': test_accuracy\n",
    "}, 'protest_detection_model.pt')\n",
    "\n",
    "print(f\"Model saved to protest_detection_model.pt with test accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p4ng4_Dkw9CI"
   },
   "outputs": [],
   "source": [
    "train=np.array(train)\n",
    "label=np.array(label)\n",
    "label=label.reshape(label.shape[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "902Px0KIw9CI"
   },
   "outputs": [],
   "source": [
    "es=EarlyStopping(monitor='val_acc',mode=max,verbose=1,patience=3)\n",
    "mc=ModelCheckpoint('best_model.h5',monitor='val_acc',mode=max,verbose=1,save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tu7fdFwGw9CI"
   },
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "optimizer = SGD(lr=lr, decay=1e-6, momentum=0.9, nesterov=True) # Adam(lr=lr, decay=0.01)\n",
    "model_resnet.compile(optimizer=optimizer, loss=keras.losses.binary_crossentropy, metrics=['accuracy'])\n",
    "# model.summary()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VqJ8dfEPw9CJ"
   },
   "outputs": [],
   "source": [
    "history=model_resnet.fit(train,label,epochs=10,batch_size=10,verbose=1,validation_split=0.35,shuffle=True,callbacks=[es,mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0DBJsebVw9CJ"
   },
   "outputs": [],
   "source": [
    "model=keras.models.load_model('best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gxL1-zwFw9CJ"
   },
   "outputs": [],
   "source": [
    "accu = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "plt.plot(accu, label=\"Accuracy\")\n",
    "plt.plot(val_acc)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend(['Acc', 'val_acc'])\n",
    "plt.plot(np.argmax(history.history[\"val_acc\"]), np.max(history.history[\"val_acc\"]), marker=\"x\", color=\"r\",\n",
    "         label=\"best model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BTUSjsNKw9CJ"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.title(\"Learning curve\")\n",
    "plt.plot(history.history[\"loss\"], label=\"loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.argmin(history.history[\"val_loss\"]), np.min(history.history[\"val_loss\"]), marker=\"x\", color=\"r\",\n",
    "         label=\"best model\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Binary CrossEntropy\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6mEmQcxbw9CJ"
   },
   "outputs": [],
   "source": [
    "test=np.array(test)\n",
    "\n",
    "predict=model.predict(test)\n",
    "predict=np.squeeze(predict,axis=1)\n",
    "for i in range(predict.shape[0]):\n",
    "    if(predict[i]<0.5):\n",
    "        predict[i]=0\n",
    "    else:\n",
    "        predict[i]=1\n",
    "\n",
    "\n",
    "label2=np.array(label2)\n",
    "print(\"Accuracy: \",round(accuracy_score(predict,label2)*100,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lxvwAsWlw9CJ"
   },
   "outputs": [],
   "source": [
    "model.save('besttt_model.h5')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Protest Dectection",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (violent_protest_final - GPU)",
   "language": "python",
   "name": "violent_protest_final"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
